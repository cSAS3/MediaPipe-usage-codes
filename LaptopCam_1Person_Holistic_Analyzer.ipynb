{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqXZw5kWgYH-",
        "outputId": "f2163143-a0ca-42f2-993d-3ecccf0a6828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#@title 依存パッケージのインストール\n",
        "%pip -q install mediapipe==0.10.14 opencv-python pandas numpy pyarrow tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 解析対象の動画ファイルをアップロード（1ファイル）\n",
        "from google.colab import files\n",
        "up = files.upload()  # ここで動画(.mp4 等)を選択\n",
        "assert len(up) == 1, \"1ファイルのみアップロードしてください。\"\n",
        "VIDEO_PATH = list(up.keys())[0]\n",
        "print(\"Uploaded:\", VIDEO_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "8FBUZZbqgZt6",
        "outputId": "251c29f2-f006-4a52-8bd6-c79fcec6d0d3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-46556494-f87f-4249-8349-2ef4650d7370\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-46556494-f87f-4249-8349-2ef4650d7370\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving WIN_20250829_12_11_22_Pro.mp4 to WIN_20250829_12_11_22_Pro.mp4\n",
            "Uploaded: WIN_20250829_12_11_22_Pro.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 解析実行セル（実行するだけでOK）\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import mediapipe as mp\n",
        "\n",
        "# ---- パラメータ（必要に応じて調整） ----\n",
        "PROCESS_MAX_SIDE = 1280   # 推論入力の最大辺長（高速化のためリサイズ）。原寸で良ければ None\n",
        "MIN_DET_CONF = 0.5        # 検出信頼度しきい値\n",
        "MIN_TRK_CONF = 0.5        # トラッキング信頼度しきい値\n",
        "DRAW_SCALE = 1.0          # オーバーレイの線太さスケール\n",
        "FLUSH_INTERVAL = 300      # CSVストリーム出力のフレーム数間隔（メモリ節約）\n",
        "DETAILED_INDEX_LABEL = True  # 詳細動画で各キーポイント番号を表示\n",
        "\n",
        "# ---- 出力先の準備 ----\n",
        "base = Path(VIDEO_PATH).stem\n",
        "out_dir = Path(f\"/content/output_{base}\")\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "overlay_detailed_path = str(out_dir / f\"{base}_overlay_detailed.mp4\")\n",
        "overlay_simple_path   = str(out_dir / f\"{base}_overlay_simple.mp4\")\n",
        "long_csv_path         = str(out_dir / f\"{base}_landmarks_long.csv\")\n",
        "summary_csv_path      = str(out_dir / f\"{base}_summary_metrics.csv\")\n",
        "schema_json_path      = str(out_dir / f\"{base}_schema_and_legend.json\")\n",
        "\n",
        "# ---- MediaPipe のインデックスと名前（後解析と可視化のため） ----\n",
        "POSE_NAMES = {\n",
        "    0:\"nose\",1:\"left_eye_inner\",2:\"left_eye\",3:\"left_eye_outer\",4:\"right_eye_inner\",5:\"right_eye\",6:\"right_eye_outer\",\n",
        "    7:\"left_ear\",8:\"right_ear\",9:\"mouth_left\",10:\"mouth_right\",11:\"left_shoulder\",12:\"right_shoulder\",13:\"left_elbow\",\n",
        "    14:\"right_elbow\",15:\"left_wrist\",16:\"right_wrist\",17:\"left_pinky\",18:\"right_pinky\",19:\"left_index\",20:\"right_index\",\n",
        "    21:\"left_thumb\",22:\"right_thumb\",23:\"left_hip\",24:\"right_hip\",25:\"left_knee\",26:\"right_knee\",27:\"left_ankle\",\n",
        "    28:\"right_ankle\",29:\"left_heel\",30:\"right_heel\",31:\"left_foot_index\",32:\"right_foot_index\"\n",
        "}\n",
        "HAND_NAMES = {\n",
        "    0:\"wrist\",1:\"thumb_cmc\",2:\"thumb_mcp\",3:\"thumb_ip\",4:\"thumb_tip\",\n",
        "    5:\"index_mcp\",6:\"index_pip\",7:\"index_dip\",8:\"index_tip\",\n",
        "    9:\"middle_mcp\",10:\"middle_pip\",11:\"middle_dip\",12:\"middle_tip\",\n",
        "    13:\"ring_mcp\",14:\"ring_pip\",15:\"ring_dip\",16:\"ring_tip\",\n",
        "    17:\"pinky_mcp\",18:\"pinky_pip\",19:\"pinky_dip\",20:\"pinky_tip\"\n",
        "}\n",
        "# 顔の唇コンター（MediaPipe FaceMeshの代表インデックス）\n",
        "LIPS_OUTER = [61,146,91,181,84,17,314,405,321,375,291]\n",
        "LIPS_INNER = [78,95,88,178,87,14,317,402,318,324,308]\n",
        "\n",
        "# ---- 色定義（BGR） ----\n",
        "COLOR_POSE = (0, 255, 255)        # 体（シアン）\n",
        "COLOR_LH   = (0, 255, 0)          # 左手（緑）\n",
        "COLOR_RH   = (0, 0, 255)          # 右手（赤）\n",
        "COLOR_LIPS_OUT = (255, 0, 255)    # 唇外周（マゼンタ）\n",
        "COLOR_LIPS_IN  = (180, 0, 180)    # 唇内周（濃いマゼンタ）\n",
        "COLOR_TEXT_BG  = (0, 0, 0)\n",
        "COLOR_TEXT_FG  = (255, 255, 255)\n",
        "\n",
        "# ---- 接続（スケルトン） ----\n",
        "POSE_CONNECTIONS = list(mp.solutions.pose.POSE_CONNECTIONS)\n",
        "HAND_CONNECTIONS = list(mp.solutions.hands.HAND_CONNECTIONS)\n",
        "\n",
        "# ---- ユーティリティ ----\n",
        "def put_text_with_bg(img, text, org, scale=0.4, thickness=1, fg=COLOR_TEXT_FG, bg=COLOR_TEXT_BG):\n",
        "    (w, h), baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, scale, thickness)\n",
        "    x, y = org\n",
        "    cv2.rectangle(img, (x, y-h-baseline), (x+w, y+baseline//2), bg, -1)\n",
        "    cv2.putText(img, text, (x, y), cv2.FONT_HERSHEY_SIMPLEX, scale, fg, thickness, cv2.LINE_AA)\n",
        "\n",
        "def clamp01(x):\n",
        "    return max(0.0, min(1.0, x))\n",
        "\n",
        "def norm_to_pix(x_norm, y_norm, w, h, flip_back=True):\n",
        "    # 解析は左右反転済み：元向きに戻すには x を 1 - x にする\n",
        "    x = (1.0 - x_norm) if flip_back else x_norm\n",
        "    return int(round(clamp01(x) * (w-1))), int(round(clamp01(y_norm) * (h-1)))\n",
        "\n",
        "def angle_deg(a, b, c):\n",
        "    # 3点 a-b-c での∠B を度で返す（a,b,c は (x,y)）\n",
        "    ba = np.array([a[0]-b[0], a[1]-b[1]], dtype=float)\n",
        "    bc = np.array([c[0]-b[0], c[1]-b[1]], dtype=float)\n",
        "    na = np.linalg.norm(ba); nc = np.linalg.norm(bc)\n",
        "    if na < 1e-6 or nc < 1e-6:\n",
        "        return np.nan\n",
        "    cosang = np.dot(ba, bc) / (na*nc)\n",
        "    cosang = max(-1.0, min(1.0, cosang))\n",
        "    return math.degrees(math.acos(cosang))\n",
        "\n",
        "def distance(p, q):\n",
        "    return float(np.linalg.norm(np.array(p, dtype=float) - np.array(q, dtype=float)))\n",
        "\n",
        "def ensure_fps(fps):\n",
        "    # 一部の動画で fps=0 が返ることがある\n",
        "    return fps if fps and fps > 1e-3 else 30.0\n",
        "\n",
        "# ---- 動画I/Oの準備 ----\n",
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "assert cap.isOpened(), \"動画を開けませんでした。ファイル形式をご確認ください。\"\n",
        "\n",
        "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "FPS = ensure_fps(cap.get(cv2.CAP_PROP_FPS))\n",
        "N   = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) if cap.get(cv2.CAP_PROP_FRAME_COUNT) > 0 else None\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "vw_detail = cv2.VideoWriter(overlay_detailed_path, fourcc, FPS, (W, H))\n",
        "vw_simple = cv2.VideoWriter(overlay_simple_path,   fourcc, FPS, (W, H))\n",
        "\n",
        "# ---- CSV（長い形式）のストリーム出力を準備 ----\n",
        "long_header = [\"frame\",\"time_ms\",\"part\",\"side\",\"landmark_index\",\"name\",\"x\",\"y\",\"z_norm\",\"visibility\",\"world_x\",\"world_y\",\"world_z\"]\n",
        "first_chunk_written = False\n",
        "\n",
        "# 要約CSVの準備\n",
        "summary_rows = []\n",
        "summary_header = [\n",
        "    \"frame\",\"time_ms\",\n",
        "    \"mouth_open_px\",\"mouth_width_px\",\"mouth_open_ratio\",\n",
        "    \"left_hand_open\",\"right_hand_open\",\n",
        "    \"left_elbow_deg\",\"right_elbow_deg\"\n",
        "]\n",
        "\n",
        "# スキーマ（インデックス→名前・色・凡例）\n",
        "schema = {\n",
        "    \"pose_names\": POSE_NAMES,\n",
        "    \"hand_names\": HAND_NAMES,\n",
        "    \"lips_indices\": {\n",
        "        \"outer\": LIPS_OUTER,\n",
        "        \"inner\": LIPS_INNER\n",
        "    },\n",
        "    \"colors_bgr\": {\n",
        "        \"pose\": COLOR_POSE,\n",
        "        \"left_hand\": COLOR_LH,\n",
        "        \"right_hand\": COLOR_RH,\n",
        "        \"lips_outer\": COLOR_LIPS_OUT,\n",
        "        \"lips_inner\": COLOR_LIPS_IN\n",
        "    },\n",
        "    \"notes\": {\n",
        "        \"orientation\": \"解析は鏡像で実施し、保存する座標・動画は元動画と同じ向き（非反転）に戻しています。\",\n",
        "        \"coordinates\": \"x, y はピクセル座標（左上原点、右向きx・下向きy）。z_norm はMediaPipeの正規化zです。world_* はPose/Handsの世界座標（xは鏡像補正で符号反転）。\"\n",
        "    }\n",
        "}\n",
        "with open(schema_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(schema, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# ---- MediaPipe 初期化（Holisticで一括推論） ----\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_dspec = mp.solutions.drawing_styles\n",
        "holistic = mp.solutions.holistic.Holistic(\n",
        "    static_image_mode=False,\n",
        "    model_complexity=2,\n",
        "    refine_face_landmarks=True,\n",
        "    enable_segmentation=False,\n",
        "    min_detection_confidence=MIN_DET_CONF,\n",
        "    min_tracking_confidence=MIN_TRK_CONF,\n",
        ")\n",
        "\n",
        "# ---- メインループ ----\n",
        "pbar = tqdm(total=N if N else 0, desc=\"Processing\", disable=(N is None))\n",
        "rows_buf = []\n",
        "\n",
        "frame_idx = 0\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 元フレーム（非反転）\n",
        "    orig_bgr = frame\n",
        "    h, w = orig_bgr.shape[:2]\n",
        "\n",
        "    # 解析用に左右反転＆（必要なら）縮小\n",
        "    anal_bgr = cv2.flip(orig_bgr, 1)\n",
        "    if PROCESS_MAX_SIDE is not None:\n",
        "        scale = min(1.0, PROCESS_MAX_SIDE / max(h, w))\n",
        "    else:\n",
        "        scale = 1.0\n",
        "    if scale < 1.0:\n",
        "        anal_bgr = cv2.resize(anal_bgr, (int(w*scale), int(h*scale)), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # MediaPipe は RGB 入力\n",
        "    anal_rgb = cv2.cvtColor(anal_bgr, cv2.COLOR_BGR2RGB)\n",
        "    res = holistic.process(anal_rgb)\n",
        "\n",
        "    # 正規化 → 元向きピクセル座標に戻す\n",
        "    def to_pix_list(landmarks, have_world=False):\n",
        "        pix = []\n",
        "        world = []\n",
        "        if landmarks is None:\n",
        "            return None, None\n",
        "        for lm in landmarks.landmark:\n",
        "            x_px, y_px = norm_to_pix(lm.x, lm.y, w, h, flip_back=True)\n",
        "            pix.append((x_px, y_px, lm.z))\n",
        "            if have_world:\n",
        "                # world座標は鏡像補正としてxの符号を反転\n",
        "                world.append((-lm.x, lm.y, lm.z))  # 注意: MediaPipeのworldはm単位・相対座標（ここは概念上）\n",
        "            else:\n",
        "                world.append((None, None, None))\n",
        "        return pix, world\n",
        "\n",
        "    # Pose\n",
        "    pose_pix, pose_world = (None, None)\n",
        "    if res.pose_landmarks:\n",
        "        pose_pix, pose_world = to_pix_list(res.pose_landmarks, have_world=False)  # holisticはpose_world_landmarksもある\n",
        "    # Hands\n",
        "    lh_pix, lh_world = (None, None)\n",
        "    rh_pix, rh_world = (None, None)\n",
        "    if res.left_hand_landmarks:\n",
        "        # 解析は鏡像入力なので、元向きでは左右が入れ替わる：保存時は Right として扱う\n",
        "        rh_pix, rh_world = to_pix_list(res.left_hand_landmarks, have_world=False)\n",
        "    if res.right_hand_landmarks:\n",
        "        # 解析は鏡像入力なので、元向きでは左右が入れ替わる：保存時は Left として扱う\n",
        "        lh_pix, lh_world = to_pix_list(res.right_hand_landmarks, have_world=False)\n",
        "    # Face（唇の外周・内周のみ抽出）\n",
        "    lips_outer_pts = []\n",
        "    lips_inner_pts = []\n",
        "    if res.face_landmarks:\n",
        "        fl = res.face_landmarks.landmark\n",
        "        for idx in LIPS_OUTER:\n",
        "            x_px, y_px = norm_to_pix(fl[idx].x, fl[idx].y, w, h, flip_back=True)\n",
        "            lips_outer_pts.append((x_px, y_px, fl[idx].z))\n",
        "        for idx in LIPS_INNER:\n",
        "            x_px, y_px = norm_to_pix(fl[idx].x, fl[idx].y, w, h, flip_back=True)\n",
        "            lips_inner_pts.append((x_px, y_px, fl[idx].z))\n",
        "\n",
        "    # ---- 長い形式CSVへ追記用レコード作成 ----\n",
        "    t_ms = int(round(1000.0 * frame_idx / FPS))\n",
        "    # Pose 33点\n",
        "    if pose_pix is not None:\n",
        "        for i, (x, y, z) in enumerate(pose_pix):\n",
        "            name = POSE_NAMES.get(i, \"\")\n",
        "            # MediaPipe Poseには visibility があるが holistic.pose_landmarks.landmark[i].visibility 取得には res.pose_landmarks を参照\n",
        "            vis = res.pose_landmarks.landmark[i].visibility if res.pose_landmarks else None\n",
        "            rows_buf.append([frame_idx, t_ms, \"pose\", None, i, name, x, y, z, vis, None, None, None])\n",
        "    # Left/Right hands（元向きでの左右に注意）\n",
        "    if lh_pix is not None:\n",
        "        for i, (x, y, z) in enumerate(lh_pix):\n",
        "            rows_buf.append([frame_idx, t_ms, \"hand\", \"Left\", i, HAND_NAMES.get(i, \"\"), x, y, z, None, None, None, None])\n",
        "    if rh_pix is not None:\n",
        "        for i, (x, y, z) in enumerate(rh_pix):\n",
        "            rows_buf.append([frame_idx, t_ms, \"hand\", \"Right\", i, HAND_NAMES.get(i, \"\"), x, y, z, None, None, None, None])\n",
        "    # Lips (outer/inner)\n",
        "    for k, pts in [(\"lips_outer\", lips_outer_pts), (\"lips_inner\", lips_inner_pts)]:\n",
        "        for j, (x, y, z) in enumerate(pts):\n",
        "            rows_buf.append([frame_idx, t_ms, k, None, j, k, x, y, z, None, None, None, None])\n",
        "\n",
        "    # ---- 要約指標の計算 ----\n",
        "    # 口の開閉\n",
        "    def safe_get(pt_list, idx):\n",
        "        return (pt_list[idx][0], pt_list[idx][1]) if pt_list and idx < len(pt_list) else None\n",
        "\n",
        "    mouth_open_px = mouth_width_px = mouth_ratio = np.nan\n",
        "    # 内唇の上下（13,14）と口角（61,291）を使う\n",
        "    if res.face_landmarks:\n",
        "        fl = res.face_landmarks.landmark\n",
        "        def n2p(i):\n",
        "            return norm_to_pix(fl[i].x, fl[i].y, w, h, flip_back=True)\n",
        "        upper = n2p(13); lower = n2p(14); leftc = n2p(61); rightc = n2p(291)\n",
        "        if upper and lower and leftc and rightc:\n",
        "            mouth_open_px  = distance(upper, lower)\n",
        "            mouth_width_px = distance(leftc, rightc)\n",
        "            mouth_ratio    = (mouth_open_px / mouth_width_px) if mouth_width_px > 1e-6 else np.nan\n",
        "\n",
        "    # 手の開き（各指先-手首距離の平均 / 手の基準長）\n",
        "    def hand_open(hand_pix):\n",
        "        if hand_pix is None:\n",
        "            return np.nan\n",
        "        wrist = hand_pix[0][:2]\n",
        "        # 中指MCP(9)を基準長に\n",
        "        base = distance(wrist, hand_pix[9][:2]) if len(hand_pix) > 9 else 0.0\n",
        "        tips = [4,8,12,16,20]\n",
        "        dists = [distance(wrist, hand_pix[i][:2]) for i in tips if len(hand_pix) > i]\n",
        "        if base < 1e-6 or len(dists) == 0:\n",
        "            return np.nan\n",
        "        return float(np.mean(dists) / base)\n",
        "\n",
        "    left_hand_open  = hand_open(lh_pix)\n",
        "    right_hand_open = hand_open(rh_pix)\n",
        "\n",
        "    # 肘角度（左：11-13-15, 右：12-14-16）\n",
        "    left_elbow_deg = right_elbow_deg = np.nan\n",
        "    if pose_pix is not None and len(pose_pix) >= 17:\n",
        "        l_sh, l_el, l_wr = pose_pix[11][:2], pose_pix[13][:2], pose_pix[15][:2]\n",
        "        r_sh, r_el, r_wr = pose_pix[12][:2], pose_pix[14][:2], pose_pix[16][:2]\n",
        "        left_elbow_deg  = angle_deg(l_sh, l_el, l_wr)\n",
        "        right_elbow_deg = angle_deg(r_sh, r_el, r_wr)\n",
        "\n",
        "    summary_rows.append([\n",
        "        frame_idx, t_ms,\n",
        "        mouth_open_px, mouth_width_px, mouth_ratio,\n",
        "        left_hand_open, right_hand_open,\n",
        "        left_elbow_deg, right_elbow_deg\n",
        "    ])\n",
        "\n",
        "    # ---- オーバーレイ描画（元向きのまま） ----\n",
        "    detailed = orig_bgr.copy()\n",
        "    simple   = orig_bgr.copy()\n",
        "\n",
        "    # スケール（解像度に応じた太さと半径）\n",
        "    thk = max(1, int(2 * DRAW_SCALE))\n",
        "    rad = max(1, int(2 * DRAW_SCALE))\n",
        "    thk_bold = max(2, int(4 * DRAW_SCALE))\n",
        "    rad_bold = max(2, int(3 * DRAW_SCALE))\n",
        "\n",
        "    # 体：スケルトン＆点\n",
        "    if pose_pix is not None:\n",
        "        # 線\n",
        "        for (i, j) in POSE_CONNECTIONS:\n",
        "            if i < len(pose_pix) and j < len(pose_pix):\n",
        "                pi = (pose_pix[i][0], pose_pix[i][1])\n",
        "                pj = (pose_pix[j][0], pose_pix[j][1])\n",
        "                cv2.line(detailed, pi, pj, COLOR_POSE, thk)\n",
        "                cv2.line(simple,   pi, pj, COLOR_POSE, thk_bold)\n",
        "        # 点＋番号（詳細）\n",
        "        for i, (x, y, _) in enumerate(pose_pix):\n",
        "            cv2.circle(detailed, (x, y), rad, COLOR_POSE, -1)\n",
        "            if DETAILED_INDEX_LABEL:\n",
        "                put_text_with_bg(detailed, f\"P{i}\", (x+4, y-4), scale=0.45, thickness=1)\n",
        "        # 簡易では点は省略（線だけ）\n",
        "\n",
        "    # 手：左\n",
        "    if lh_pix is not None:\n",
        "        for (i, j) in HAND_CONNECTIONS:\n",
        "            if i < len(lh_pix) and j < len(lh_pix):\n",
        "                cv2.line(detailed, (lh_pix[i][0], lh_pix[i][1]), (lh_pix[j][0], lh_pix[j][1]), COLOR_LH, thk)\n",
        "                cv2.line(simple,   (lh_pix[i][0], lh_pix[i][1]), (lh_pix[j][0], lh_pix[j][1]), COLOR_LH, thk_bold)\n",
        "        for i, (x, y, _) in enumerate(lh_pix):\n",
        "            cv2.circle(detailed, (x, y), rad, COLOR_LH, -1)\n",
        "            if DETAILED_INDEX_LABEL:\n",
        "                put_text_with_bg(detailed, f\"L{i}\", (x+3, y-3), scale=0.45, thickness=1, fg=(0,0,0), bg=(180,255,180))\n",
        "\n",
        "    # 手：右\n",
        "    if rh_pix is not None:\n",
        "        for (i, j) in HAND_CONNECTIONS:\n",
        "            if i < len(rh_pix) and j < len(rh_pix):\n",
        "                cv2.line(detailed, (rh_pix[i][0], rh_pix[i][1]), (rh_pix[j][0], rh_pix[j][1]), COLOR_RH, thk)\n",
        "                cv2.line(simple,   (rh_pix[i][0], rh_pix[i][1]), (rh_pix[j][0], rh_pix[j][1]), COLOR_RH, thk_bold)\n",
        "        for i, (x, y, _) in enumerate(rh_pix):\n",
        "            cv2.circle(detailed, (x, y), rad, COLOR_RH, -1)\n",
        "            if DETAILED_INDEX_LABEL:\n",
        "                put_text_with_bg(detailed, f\"R{i}\", (x+3, y-3), scale=0.45, thickness=1, fg=(255,255,255), bg=(80,80,180))\n",
        "\n",
        "    # 唇（外周・内周）\n",
        "    def draw_poly(points, img_detail, img_simple, color, label_prefix):\n",
        "        if len(points) >= 2:\n",
        "            # ポリライン（閉曲線にしたいので最初を最後に追加）\n",
        "            pts = np.array([(p[0], p[1]) for p in points] + [(points[0][0], points[0][1])], dtype=np.int32)\n",
        "            cv2.polylines(img_detail, [pts], isClosed=True, color=color, thickness=thk)\n",
        "            cv2.polylines(img_simple, [pts], isClosed=True, color=color, thickness=thk_bold)\n",
        "            # 詳細：点と番号\n",
        "            for k, (x, y, _) in enumerate(points):\n",
        "                cv2.circle(img_detail, (x, y), rad, color, -1)\n",
        "                if DETAILED_INDEX_LABEL:\n",
        "                    put_text_with_bg(img_detail, f\"{label_prefix}{k}\", (x+2, y-2), scale=0.45, thickness=1)\n",
        "\n",
        "    if lips_outer_pts:\n",
        "        draw_poly(lips_outer_pts, detailed, simple, COLOR_LIPS_OUT, \"Lo\")\n",
        "    if lips_inner_pts:\n",
        "        draw_poly(lips_inner_pts, detailed, simple, COLOR_LIPS_IN,  \"Li\")\n",
        "\n",
        "    # 2本の動画に書き込み\n",
        "    vw_detail.write(detailed)\n",
        "    vw_simple.write(simple)\n",
        "\n",
        "    # 長い形式CSV：バッファを一定間隔でフラッシュ\n",
        "    if (frame_idx + 1) % FLUSH_INTERVAL == 0:\n",
        "        df_chunk = pd.DataFrame(rows_buf, columns=long_header)\n",
        "        mode = \"w\" if not first_chunk_written else \"a\"\n",
        "        header = not first_chunk_written\n",
        "        df_chunk.to_csv(long_csv_path, index=False, mode=mode, header=header, encoding=\"utf-8\")\n",
        "        rows_buf = []\n",
        "        first_chunk_written = True\n",
        "\n",
        "    frame_idx += 1\n",
        "    if N:\n",
        "        pbar.update(1)\n",
        "\n",
        "# ループ終了後のフラッシュ\n",
        "if rows_buf:\n",
        "    df_chunk = pd.DataFrame(rows_buf, columns=long_header)\n",
        "    mode = \"w\" if not first_chunk_written else \"a\"\n",
        "    header = not first_chunk_written\n",
        "    df_chunk.to_csv(long_csv_path, index=False, mode=mode, header=header, encoding=\"utf-8\")\n",
        "    rows_buf = []\n",
        "    first_chunk_written = True\n",
        "\n",
        "cap.release()\n",
        "vw_detail.release()\n",
        "vw_simple.release()\n",
        "holistic.close()\n",
        "pbar.close()\n",
        "\n",
        "# 要約CSVを保存\n",
        "pd.DataFrame(summary_rows, columns=summary_header).to_csv(summary_csv_path, index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"== 完了 ==\")\n",
        "print(\"出力フォルダ:\", out_dir)\n",
        "print(\"詳細オーバーレイ: \", overlay_detailed_path)\n",
        "print(\"簡易オーバーレイ: \", overlay_simple_path)\n",
        "print(\"長い形式CSV:      \", long_csv_path)\n",
        "print(\"要約CSV:          \", summary_csv_path)\n",
        "print(\"スキーマJSON:     \", schema_json_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wAKCu6Ugdwb",
        "outputId": "fd534349-b3f3-43df-8c8d-8c8af3c257ab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading model to /usr/local/lib/python3.12/dist-packages/mediapipe/modules/pose_landmark/pose_landmark_heavy.tflite\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   0%|          | 0/482 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
            "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
            "Processing: 100%|██████████| 482/482 [02:13<00:00,  3.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== 完了 ==\n",
            "出力フォルダ: /content/output_WIN_20250829_12_11_22_Pro\n",
            "詳細オーバーレイ:  /content/output_WIN_20250829_12_11_22_Pro/WIN_20250829_12_11_22_Pro_overlay_detailed.mp4\n",
            "簡易オーバーレイ:  /content/output_WIN_20250829_12_11_22_Pro/WIN_20250829_12_11_22_Pro_overlay_simple.mp4\n",
            "長い形式CSV:       /content/output_WIN_20250829_12_11_22_Pro/WIN_20250829_12_11_22_Pro_landmarks_long.csv\n",
            "要約CSV:           /content/output_WIN_20250829_12_11_22_Pro/WIN_20250829_12_11_22_Pro_summary_metrics.csv\n",
            "スキーマJSON:      /content/output_WIN_20250829_12_11_22_Pro/WIN_20250829_12_11_22_Pro_schema_and_legend.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}